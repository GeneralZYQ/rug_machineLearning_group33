{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading and get into proper format training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "data = scipy.io.loadmat(\"average_abs_slope_no_pca.mat\")\n",
    "\n",
    "for i in data:\n",
    "    if '__' not in i and 'readme' not in i:\n",
    "          np.savetxt((\"average_abs_slope_no_pca.csv\"),data[i],delimiter=',')\n",
    "\n",
    "# every 30 lines is a different speaker. Each recording is decomposed into 9 arrays of 4 points (9 lines from the original plot)\n",
    "with open('average_abs_slope_no_pca.csv', newline='') as csvfile:\n",
    "    data = list(csv.reader(csvfile))\n",
    "#print(len(data))\n",
    "# transform data into arrays of 5 times 12\n",
    "temp=[]\n",
    "c=[]\n",
    "i=0\n",
    "for i in range(0,1620,6):\n",
    "    #print(len(elem))\n",
    "    for t in range(6):\n",
    "        #print(\"value i=\",i)\n",
    "        #print(\"value t=\",t)\n",
    "        c+= data[i+t]\n",
    "\n",
    "    temp.append(c)\n",
    "    c=[]\n",
    "#print(\"packs of 72: \",temp[1])\n",
    "\n",
    "f=[]\n",
    "final=[]\n",
    "for elem in temp:\n",
    "    for i in range(0,72,6):\n",
    "        f.append(elem[0+i:6+i])\n",
    "    final.append(f)\n",
    "    f=[]\n",
    "#print(\"herw:\",final[0])\n",
    "x_train=final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading and get into proper shape testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "test = scipy.io.loadmat(\"average_abs_slope_no_pca_test_data.mat\")\n",
    "\n",
    "for i in test:\n",
    "    if '__' not in i and 'readme' not in i:\n",
    "          np.savetxt((\"average_abs_slope_no_pca_test_data.csv\"),test[i],delimiter=',')\n",
    "            \n",
    "# every 30 lines is a different speaker. Each recording is decomposed into 9 arrays of 4 points (9 lines from the original plot)\n",
    "with open('average_abs_slope_no_pca_test_data.csv', newline='') as csvfile:\n",
    "    test = list(csv.reader(csvfile))\n",
    "\n",
    "temp=[]\n",
    "c=[]\n",
    "i=0\n",
    "for i in range(0,2220,6):\n",
    "    #print(len(elem))\n",
    "    for t in range(6):\n",
    "        #print(\"value i=\",i)\n",
    "        #print(\"value t=\",t)\n",
    "        c+= test[i+t]\n",
    "\n",
    "    temp.append(c)\n",
    "    c=[]\n",
    "#print(\"packs of 72: \",temp[0])\n",
    "\n",
    "f=[]\n",
    "final=[]\n",
    "for elem in temp:\n",
    "    for i in range(0,72,6):\n",
    "        f.append(elem[0+i:6+i])\n",
    "    final.append(f)\n",
    "    f=[]\n",
    "x_test=final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create labels and do one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_encoded = []\n",
    "for i in range(9):\n",
    "    integer_encoded += [i] * 30\n",
    "\n",
    "onehot_encoded = []\n",
    "for elem in integer_encoded:\n",
    "    letter = [0 for i in range(9)]\n",
    "    letter[elem] = 1\n",
    "    onehot_encoded.append(letter)\n",
    "\n",
    "y_train=onehot_encoded\n",
    "\n",
    "\n",
    "# generate labels for the training \n",
    "integer_encoded = [0]*31 + [1]*35 + [2]*88 + [3]*44 + [4]*29 + [5]*24 + [6]*40 + [7]*50 + [8]*29\n",
    "\n",
    "onehot_encoded = []\n",
    "for elem in integer_encoded:\n",
    "    letter = [0 for i in range(9)]\n",
    "    letter[elem] = 1\n",
    "    onehot_encoded.append(letter)\n",
    "\n",
    "y_test=onehot_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put strings into floats for both training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def Convert_to_list_of_ints(data): \n",
    "    t=[]\n",
    "    c=[]\n",
    "    # there are 270 elements\n",
    "    for elem in data:\n",
    "        for i in range(12):\n",
    "            temp=[float(x) for x in elem[i]]\n",
    "            c.append(temp) #concatenate the sub arrays for each of the 9 lines to make one big array\n",
    "        t.append(c)\n",
    "        c=[]\n",
    "    return t\n",
    "\n",
    "x_train=Convert_to_list_of_ints(x_train)\n",
    "x_test=Convert_to_list_of_ints(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffling training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# shuffle training data\n",
    "c = list(zip(x_train, y_train))\n",
    "random.shuffle(c)\n",
    "x_train, y_train = zip(*c)\n",
    "\n",
    "## Turn the lists into np.arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "## we also have to convert our data into three-dimensional format\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 6,12))\n",
    "\n",
    "# shuffle testing data\n",
    "b = list(zip(x_test, y_test))\n",
    "random.shuffle(b)\n",
    "x_test, y_test = zip(*b)\n",
    "\n",
    "## Turn the lists into np.arrays\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "\n",
    "## we also have to convert our data into three-dimensional format\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 6,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62\n",
      "  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80\n",
      "  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26]\n",
      "Running Fold 1 / 10\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.2716\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 528us/step - loss: 0.0803 - accuracy: 0.4938\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 458us/step - loss: 0.0722 - accuracy: 0.6420\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 545us/step - loss: 0.0646 - accuracy: 0.7119\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 487us/step - loss: 0.0617 - accuracy: 0.6955\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 455us/step - loss: 0.0599 - accuracy: 0.7078\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 523us/step - loss: 0.0553 - accuracy: 0.7531\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 587us/step - loss: 0.0548 - accuracy: 0.7737\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 530us/step - loss: 0.0545 - accuracy: 0.7490\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 464us/step - loss: 0.0492 - accuracy: 0.7984\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 474us/step - loss: 0.0516 - accuracy: 0.7819\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 506us/step - loss: 0.0507 - accuracy: 0.8148\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 533us/step - loss: 0.0503 - accuracy: 0.7942\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 492us/step - loss: 0.0475 - accuracy: 0.8313\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 637us/step - loss: 0.0437 - accuracy: 0.8807\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 543us/step - loss: 0.0460 - accuracy: 0.8025\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 473us/step - loss: 0.0462 - accuracy: 0.8272\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 481us/step - loss: 0.0442 - accuracy: 0.8354\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 550us/step - loss: 0.0401 - accuracy: 0.8889\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 605us/step - loss: 0.0424 - accuracy: 0.8354\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 555us/step - loss: 0.0402 - accuracy: 0.8477\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 484us/step - loss: 0.0414 - accuracy: 0.8436\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 447us/step - loss: 0.0400 - accuracy: 0.8601\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 535us/step - loss: 0.0395 - accuracy: 0.8683\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 488us/step - loss: 0.0397 - accuracy: 0.8683\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 448us/step - loss: 0.0424 - accuracy: 0.8313\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 447us/step - loss: 0.0391 - accuracy: 0.8601\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 522us/step - loss: 0.0398 - accuracy: 0.8519\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 611us/step - loss: 0.0350 - accuracy: 0.8848\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 500us/step - loss: 0.0384 - accuracy: 0.8642\n",
      "Test loss: 0.029227469116449356\n",
      "Test accuracy: 1.0\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  54  55  56  57  58  59  60  61  62\n",
      "  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80\n",
      "  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 51 52 53]\n",
      "Running Fold 2 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.3004\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 507us/step - loss: 0.0792 - accuracy: 0.5144\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 562us/step - loss: 0.0721 - accuracy: 0.6173\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 481us/step - loss: 0.0671 - accuracy: 0.6626\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 479us/step - loss: 0.0631 - accuracy: 0.6831\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 503us/step - loss: 0.0633 - accuracy: 0.7119\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 514us/step - loss: 0.0581 - accuracy: 0.7284\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 460us/step - loss: 0.0577 - accuracy: 0.7119\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 487us/step - loss: 0.0561 - accuracy: 0.7407\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 530us/step - loss: 0.0546 - accuracy: 0.7778\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 523us/step - loss: 0.0508 - accuracy: 0.8066\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 500us/step - loss: 0.0496 - accuracy: 0.7942\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 458us/step - loss: 0.0481 - accuracy: 0.7901\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 464us/step - loss: 0.0478 - accuracy: 0.7984\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 516us/step - loss: 0.0459 - accuracy: 0.8272\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 678us/step - loss: 0.0464 - accuracy: 0.8436\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 540us/step - loss: 0.0444 - accuracy: 0.8477\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 543us/step - loss: 0.0443 - accuracy: 0.8066\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 619us/step - loss: 0.0423 - accuracy: 0.8313\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 485us/step - loss: 0.0440 - accuracy: 0.7984\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 451us/step - loss: 0.0431 - accuracy: 0.8230\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 448us/step - loss: 0.0411 - accuracy: 0.8313\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 436us/step - loss: 0.0417 - accuracy: 0.8436\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 459us/step - loss: 0.0369 - accuracy: 0.8642\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 447us/step - loss: 0.0399 - accuracy: 0.8272\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 434us/step - loss: 0.0381 - accuracy: 0.8601\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 525us/step - loss: 0.0364 - accuracy: 0.8765\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 408us/step - loss: 0.0354 - accuracy: 0.8930\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 420us/step - loss: 0.0386 - accuracy: 0.8519\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 420us/step - loss: 0.0363 - accuracy: 0.8765\n",
      "Test loss: 0.027399301528930664\n",
      "Test accuracy: 1.0\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77\n",
      " 78 79 80]\n",
      "Running Fold 3 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.2798\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 425us/step - loss: 0.0792 - accuracy: 0.5391\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 519us/step - loss: 0.0718 - accuracy: 0.6502\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 533us/step - loss: 0.0650 - accuracy: 0.6502\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 475us/step - loss: 0.0620 - accuracy: 0.6914\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 492us/step - loss: 0.0592 - accuracy: 0.6955\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 676us/step - loss: 0.0573 - accuracy: 0.7119\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 482us/step - loss: 0.0554 - accuracy: 0.7284\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 467us/step - loss: 0.0541 - accuracy: 0.7407\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 511us/step - loss: 0.0505 - accuracy: 0.8313\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 424us/step - loss: 0.0515 - accuracy: 0.7737\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 414us/step - loss: 0.0495 - accuracy: 0.7737\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 411us/step - loss: 0.0458 - accuracy: 0.8230\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 515us/step - loss: 0.0478 - accuracy: 0.7737\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 561us/step - loss: 0.0452 - accuracy: 0.8395\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 586us/step - loss: 0.0453 - accuracy: 0.82720s - loss: 0.0460 - accuracy: 0.\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 504us/step - loss: 0.0447 - accuracy: 0.8354\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 710us/step - loss: 0.0420 - accuracy: 0.8560\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 485us/step - loss: 0.0449 - accuracy: 0.8107\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 412us/step - loss: 0.0416 - accuracy: 0.8560\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 404us/step - loss: 0.0416 - accuracy: 0.8560\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 413us/step - loss: 0.0393 - accuracy: 0.8395\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 425us/step - loss: 0.0392 - accuracy: 0.8519\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 434us/step - loss: 0.0411 - accuracy: 0.8354\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 425us/step - loss: 0.0379 - accuracy: 0.8765\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 446us/step - loss: 0.0396 - accuracy: 0.8519\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 570us/step - loss: 0.0374 - accuracy: 0.8477\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 570us/step - loss: 0.0376 - accuracy: 0.8807\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 438us/step - loss: 0.0340 - accuracy: 0.8930\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 422us/step - loss: 0.0365 - accuracy: 0.8807\n",
      "Test loss: 0.04303181543946266\n",
      "Test accuracy: 0.8148148059844971\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [ 81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107]\n",
      "Running Fold 4 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.2881\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 429us/step - loss: 0.0811 - accuracy: 0.5021\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 424us/step - loss: 0.0737 - accuracy: 0.5679\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 461us/step - loss: 0.0674 - accuracy: 0.6626\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 519us/step - loss: 0.0640 - accuracy: 0.7037\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 520us/step - loss: 0.0605 - accuracy: 0.7119\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 488us/step - loss: 0.0576 - accuracy: 0.7490\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 406us/step - loss: 0.0553 - accuracy: 0.7490\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 395us/step - loss: 0.0540 - accuracy: 0.7613\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 410us/step - loss: 0.0511 - accuracy: 0.7737\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 416us/step - loss: 0.0529 - accuracy: 0.7407\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 407us/step - loss: 0.0495 - accuracy: 0.8148\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 477us/step - loss: 0.0476 - accuracy: 0.8313\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 423us/step - loss: 0.0499 - accuracy: 0.7942\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 412us/step - loss: 0.0494 - accuracy: 0.7984\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 422us/step - loss: 0.0476 - accuracy: 0.7654\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 420us/step - loss: 0.0453 - accuracy: 0.8189\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 432us/step - loss: 0.0463 - accuracy: 0.7942\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 409us/step - loss: 0.0449 - accuracy: 0.8436\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 422us/step - loss: 0.0430 - accuracy: 0.8395\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 425us/step - loss: 0.0424 - accuracy: 0.8477\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 474us/step - loss: 0.0430 - accuracy: 0.8519\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 425us/step - loss: 0.0448 - accuracy: 0.7984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 410us/step - loss: 0.0413 - accuracy: 0.8519\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 415us/step - loss: 0.0438 - accuracy: 0.8272\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 422us/step - loss: 0.0396 - accuracy: 0.8642\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 421us/step - loss: 0.0373 - accuracy: 0.8683\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 418us/step - loss: 0.0392 - accuracy: 0.8765\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 414us/step - loss: 0.0396 - accuracy: 0.8477\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 409us/step - loss: 0.0381 - accuracy: 0.8395\n",
      "Test loss: 0.029530059546232224\n",
      "Test accuracy: 1.0\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134]\n",
      "Running Fold 5 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.2551\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 607us/step - loss: 0.0818 - accuracy: 0.5103\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 513us/step - loss: 0.0756 - accuracy: 0.6008\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 525us/step - loss: 0.0687 - accuracy: 0.6667\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 501us/step - loss: 0.0642 - accuracy: 0.7284\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 593us/step - loss: 0.0626 - accuracy: 0.7202\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 451us/step - loss: 0.0552 - accuracy: 0.7366\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 425us/step - loss: 0.0569 - accuracy: 0.7160\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 416us/step - loss: 0.0554 - accuracy: 0.7325\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 488us/step - loss: 0.0546 - accuracy: 0.7531\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 434us/step - loss: 0.0525 - accuracy: 0.7695\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 500us/step - loss: 0.0560 - accuracy: 0.7243\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 592us/step - loss: 0.0520 - accuracy: 0.7942\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 484us/step - loss: 0.0490 - accuracy: 0.8025\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 429us/step - loss: 0.0499 - accuracy: 0.7984\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 438us/step - loss: 0.0463 - accuracy: 0.8436\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 435us/step - loss: 0.0473 - accuracy: 0.8066\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 431us/step - loss: 0.0431 - accuracy: 0.8519\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 434us/step - loss: 0.0472 - accuracy: 0.7819\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 664us/step - loss: 0.0438 - accuracy: 0.8436\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 540us/step - loss: 0.0416 - accuracy: 0.8354\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 517us/step - loss: 0.0423 - accuracy: 0.8724\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 412us/step - loss: 0.0446 - accuracy: 0.8066\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 415us/step - loss: 0.0395 - accuracy: 0.8519\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 422us/step - loss: 0.0393 - accuracy: 0.8519\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 426us/step - loss: 0.0410 - accuracy: 0.8313\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 415us/step - loss: 0.0380 - accuracy: 0.8560\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 515us/step - loss: 0.0408 - accuracy: 0.8436\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 417us/step - loss: 0.0383 - accuracy: 0.8807\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 425us/step - loss: 0.0387 - accuracy: 0.8642\n",
      "Test loss: 0.026723112910985947\n",
      "Test accuracy: 0.9629629850387573\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161]\n",
      "Running Fold 6 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0953 - accuracy: 0.2469\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 447us/step - loss: 0.0817 - accuracy: 0.5267\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 403us/step - loss: 0.0724 - accuracy: 0.6132\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 490us/step - loss: 0.0677 - accuracy: 0.6584\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 425us/step - loss: 0.0638 - accuracy: 0.6831\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 409us/step - loss: 0.0628 - accuracy: 0.6626\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 422us/step - loss: 0.0576 - accuracy: 0.7366\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 433us/step - loss: 0.0574 - accuracy: 0.7202\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 425us/step - loss: 0.0572 - accuracy: 0.7037\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 428us/step - loss: 0.0538 - accuracy: 0.7654\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 444us/step - loss: 0.0535 - accuracy: 0.7243\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 493us/step - loss: 0.0514 - accuracy: 0.7901\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 570us/step - loss: 0.0523 - accuracy: 0.7613\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 455us/step - loss: 0.0504 - accuracy: 0.7860\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 443us/step - loss: 0.0467 - accuracy: 0.8148\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 437us/step - loss: 0.0490 - accuracy: 0.7695\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 525us/step - loss: 0.0458 - accuracy: 0.8107\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 438us/step - loss: 0.0439 - accuracy: 0.8230\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 415us/step - loss: 0.0436 - accuracy: 0.8025\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 412us/step - loss: 0.0441 - accuracy: 0.8436\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 408us/step - loss: 0.0425 - accuracy: 0.8354\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 428us/step - loss: 0.0418 - accuracy: 0.8519\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 459us/step - loss: 0.0384 - accuracy: 0.8765\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 468us/step - loss: 0.0417 - accuracy: 0.8189\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 422us/step - loss: 0.0391 - accuracy: 0.8477\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 436us/step - loss: 0.0404 - accuracy: 0.8642\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 427us/step - loss: 0.0384 - accuracy: 0.8477\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 561us/step - loss: 0.0381 - accuracy: 0.8519\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 598us/step - loss: 0.0389 - accuracy: 0.8601\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 535us/step - loss: 0.0385 - accuracy: 0.8395\n",
      "Test loss: 0.020510753616690636\n",
      "Test accuracy: 1.0\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188]\n",
      "Running Fold 7 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.2222\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 475us/step - loss: 0.0826 - accuracy: 0.5226\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 466us/step - loss: 0.0734 - accuracy: 0.6091\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 482us/step - loss: 0.0679 - accuracy: 0.6626\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 478us/step - loss: 0.0648 - accuracy: 0.6708\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 474us/step - loss: 0.0586 - accuracy: 0.7325\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 472us/step - loss: 0.0581 - accuracy: 0.7243\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 474us/step - loss: 0.0576 - accuracy: 0.7202\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 578us/step - loss: 0.0554 - accuracy: 0.7654\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 484us/step - loss: 0.0528 - accuracy: 0.7695\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 482us/step - loss: 0.0480 - accuracy: 0.8354\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 482us/step - loss: 0.0488 - accuracy: 0.7778\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 495us/step - loss: 0.0495 - accuracy: 0.7942\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 501us/step - loss: 0.0477 - accuracy: 0.8025\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 497us/step - loss: 0.0466 - accuracy: 0.8148\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 493us/step - loss: 0.0462 - accuracy: 0.8107\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 545us/step - loss: 0.0436 - accuracy: 0.8313\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 513us/step - loss: 0.0459 - accuracy: 0.8230\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 447us/step - loss: 0.0460 - accuracy: 0.8107\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 424us/step - loss: 0.0428 - accuracy: 0.8272\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 446us/step - loss: 0.0410 - accuracy: 0.8724\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 534us/step - loss: 0.0446 - accuracy: 0.8272\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 598us/step - loss: 0.0379 - accuracy: 0.8930\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 494us/step - loss: 0.0417 - accuracy: 0.8189\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 430us/step - loss: 0.0380 - accuracy: 0.8765\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 565us/step - loss: 0.0401 - accuracy: 0.8477\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 535us/step - loss: 0.0390 - accuracy: 0.8436\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 524us/step - loss: 0.0389 - accuracy: 0.8477\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 488us/step - loss: 0.0387 - accuracy: 0.8560\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 540us/step - loss: 0.0382 - accuracy: 0.8848\n",
      "Test loss: 0.03127327188849449\n",
      "Test accuracy: 0.8148148059844971\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215]\n",
      "Running Fold 8 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.2510\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 478us/step - loss: 0.0791 - accuracy: 0.5885\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 512us/step - loss: 0.0710 - accuracy: 0.6502\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 473us/step - loss: 0.0661 - accuracy: 0.6749\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 477us/step - loss: 0.0622 - accuracy: 0.7284\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 528us/step - loss: 0.0608 - accuracy: 0.7243\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 532us/step - loss: 0.0577 - accuracy: 0.7490\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 511us/step - loss: 0.0554 - accuracy: 0.7490\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 651us/step - loss: 0.0534 - accuracy: 0.7819\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 430us/step - loss: 0.0535 - accuracy: 0.7572\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 466us/step - loss: 0.0538 - accuracy: 0.7695\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 468us/step - loss: 0.0501 - accuracy: 0.7737\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 470us/step - loss: 0.0490 - accuracy: 0.7901\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 487us/step - loss: 0.0461 - accuracy: 0.8272\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 489us/step - loss: 0.0478 - accuracy: 0.7613\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 558us/step - loss: 0.0458 - accuracy: 0.8148\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 463us/step - loss: 0.0468 - accuracy: 0.7984\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 496us/step - loss: 0.0458 - accuracy: 0.8189\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 433us/step - loss: 0.0449 - accuracy: 0.8395\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 439us/step - loss: 0.0435 - accuracy: 0.8436\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 423us/step - loss: 0.0436 - accuracy: 0.8601\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 445us/step - loss: 0.0403 - accuracy: 0.8189\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 446us/step - loss: 0.0406 - accuracy: 0.8313\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 451us/step - loss: 0.0385 - accuracy: 0.8642\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 560us/step - loss: 0.0398 - accuracy: 0.8313\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 473us/step - loss: 0.0393 - accuracy: 0.8560\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 477us/step - loss: 0.0394 - accuracy: 0.8560\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 481us/step - loss: 0.0403 - accuracy: 0.8601\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 458us/step - loss: 0.0376 - accuracy: 0.8560\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 457us/step - loss: 0.0386 - accuracy: 0.8601\n",
      "Test loss: 0.02167973294854164\n",
      "Test accuracy: 1.0\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242]\n",
      "Running Fold 9 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.2510\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 459us/step - loss: 0.0808 - accuracy: 0.4691\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 450us/step - loss: 0.0735 - accuracy: 0.5802\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 431us/step - loss: 0.0686 - accuracy: 0.6790\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 504us/step - loss: 0.0671 - accuracy: 0.6708\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 524us/step - loss: 0.0616 - accuracy: 0.7202\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 500us/step - loss: 0.0580 - accuracy: 0.7325\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 513us/step - loss: 0.0574 - accuracy: 0.7119\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 522us/step - loss: 0.0531 - accuracy: 0.7654\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 507us/step - loss: 0.0547 - accuracy: 0.7531\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 495us/step - loss: 0.0525 - accuracy: 0.7737\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 466us/step - loss: 0.0485 - accuracy: 0.7942\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 450us/step - loss: 0.0499 - accuracy: 0.7860\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 435us/step - loss: 0.0510 - accuracy: 0.7572\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 479us/step - loss: 0.0467 - accuracy: 0.8107\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 495us/step - loss: 0.0464 - accuracy: 0.8066\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 504us/step - loss: 0.0450 - accuracy: 0.8272\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 477us/step - loss: 0.0455 - accuracy: 0.8066\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 459us/step - loss: 0.0441 - accuracy: 0.8313\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 465us/step - loss: 0.0436 - accuracy: 0.8189\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 489us/step - loss: 0.0462 - accuracy: 0.8025\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 474us/step - loss: 0.0453 - accuracy: 0.8025\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 446us/step - loss: 0.0416 - accuracy: 0.8313\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 473us/step - loss: 0.0401 - accuracy: 0.8560\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 551us/step - loss: 0.0394 - accuracy: 0.8519\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 469us/step - loss: 0.0374 - accuracy: 0.8765\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 442us/step - loss: 0.0377 - accuracy: 0.8930\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 452us/step - loss: 0.0379 - accuracy: 0.8807\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 420us/step - loss: 0.0387 - accuracy: 0.8519\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 417us/step - loss: 0.0370 - accuracy: 0.8724\n",
      "Test loss: 0.028329571709036827\n",
      "Test accuracy: 0.9629629850387573\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242] [243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269]\n",
      "Running Fold 10 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.2840\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 488us/step - loss: 0.0807 - accuracy: 0.5185\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 495us/step - loss: 0.0745 - accuracy: 0.5556\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 497us/step - loss: 0.0677 - accuracy: 0.6708\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 509us/step - loss: 0.0650 - accuracy: 0.6461\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 493us/step - loss: 0.0617 - accuracy: 0.6955\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 501us/step - loss: 0.0597 - accuracy: 0.6996\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 559us/step - loss: 0.0563 - accuracy: 0.7613\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 476us/step - loss: 0.0543 - accuracy: 0.7737\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 478us/step - loss: 0.0551 - accuracy: 0.7860\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 472us/step - loss: 0.0536 - accuracy: 0.7819\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 487us/step - loss: 0.0504 - accuracy: 0.8025\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 480us/step - loss: 0.0497 - accuracy: 0.8189\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 531us/step - loss: 0.0493 - accuracy: 0.7984\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 506us/step - loss: 0.0496 - accuracy: 0.7984\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 507us/step - loss: 0.0478 - accuracy: 0.8230\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 482us/step - loss: 0.0458 - accuracy: 0.8066\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 469us/step - loss: 0.0423 - accuracy: 0.8477\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 456us/step - loss: 0.0443 - accuracy: 0.8272\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 476us/step - loss: 0.0415 - accuracy: 0.8642\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 495us/step - loss: 0.0428 - accuracy: 0.8436\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 521us/step - loss: 0.0414 - accuracy: 0.8519\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 573us/step - loss: 0.0399 - accuracy: 0.8477\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 479us/step - loss: 0.0405 - accuracy: 0.8560\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 485us/step - loss: 0.0397 - accuracy: 0.8807\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 483us/step - loss: 0.0416 - accuracy: 0.8354\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 478us/step - loss: 0.0387 - accuracy: 0.8683\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 473us/step - loss: 0.0381 - accuracy: 0.8560\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 484us/step - loss: 0.0412 - accuracy: 0.8272\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 478us/step - loss: 0.0354 - accuracy: 0.8848\n",
      "Test loss: 0.02933054231107235\n",
      "Test accuracy: 0.9259259104728699\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding, BatchNormalization, Activation\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "##model.add(Bidirectional(LSTM(50, activation='relu',return_sequences=True,kernel_regularizer=L1L2(l1=0.0, l2=0.0)), input_shape=(x_train.shape[1], 9)))\n",
    "    model.add(LSTM(units=90,activation='tanh', recurrent_activation='sigmoid', return_sequences=False,input_shape=(x_train.shape[1], 12),dropout=0.2,recurrent_dropout=0.2)) \n",
    "##model.add(BatchNormalization())\n",
    "##model.add(LSTM(units=90,activation='relu', recurrent_activation='sigmoid', return_sequences=True,dropout=0.34,recurrent_dropout=0.34))\n",
    "##model.add(LSTM(units=90, activation='relu', recurrent_activation='sigmoid',return_sequences=False,dropout=0.34,recurrent_dropout=0.34))\n",
    "    model.add(Dense(units=9))\n",
    "    model.add(Activation(\"linear\")) \n",
    "    opt= keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer = opt, loss = 'mean_squared_error',metrics = ['accuracy'])\n",
    "    return model\n",
    "#model.fit(x_train, y_train, batch_size=27, epochs=2) #was 150\n",
    "\n",
    "# saving the model\n",
    "#model.save('keras_ML1.h5')\n",
    "\n",
    "\n",
    "#FIRST TEST K-FOLD\n",
    "def train_and_evaluate_model(model, data, labels, Data, Labels):\n",
    "    model.fit(data, labels, batch_size=9, epochs=30) #was 150 #training subset\n",
    "    score = model.evaluate(Data, Labels, verbose=0) #testing subset\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    return score\n",
    "    # fit and evaluate here.\n",
    "\n",
    "Test_Loss = []\n",
    "Test_Accuracy = []\n",
    "    \n",
    "from sklearn.model_selection import KFold\n",
    "#if __name__ == \"__main__\":\n",
    "data, labels = x_train, y_train\n",
    "kf = KFold(n_splits=10) \n",
    "i=0\n",
    "for train, test in kf.split(x_train):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "    i=i+1\n",
    "    print(\"Running Fold\", i,\"/\", 10)\n",
    "    model = None # Clearing the NN.\n",
    "    model = create_model()\n",
    "    score = train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])\n",
    "    Test_Loss.append(score[0])\n",
    "    Test_Accuracy.append(score[1])\n",
    "    \n",
    "model.save('keras_ML3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 0.8148148059844971,\n",
       " 1.0,\n",
       " 0.9629629850387573,\n",
       " 1.0,\n",
       " 0.8148148059844971,\n",
       " 1.0,\n",
       " 0.9629629850387573,\n",
       " 0.9259259104728699]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.02474042879971298\n",
      "Test accuracy: 0.9594594836235046\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# testing the model\n",
    "model = load_model('keras_ML3.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97        31\n",
      "          1       0.85      0.94      0.89        35\n",
      "          2       1.00      0.94      0.97        88\n",
      "          3       1.00      0.95      0.98        44\n",
      "          4       0.88      1.00      0.94        29\n",
      "          5       0.96      1.00      0.98        24\n",
      "          6       1.00      0.97      0.99        40\n",
      "          7       0.92      0.98      0.95        50\n",
      "          8       1.00      0.93      0.96        29\n",
      "\n",
      "avg / total       0.96      0.96      0.96       370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(x_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
