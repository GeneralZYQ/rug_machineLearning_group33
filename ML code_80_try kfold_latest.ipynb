{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load traning data and do one-hot encoding on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# every 30 lines is a different speaker. Each recording is decomposed into 9 arrays of 4 points (9 lines from the original plot)\n",
    "with open('training_after_PCA_after_taking_5.csv', newline='') as csvfile:\n",
    "    data = list(csv.reader(csvfile))\n",
    "\n",
    "# generate labels for the training \n",
    "integer_encoded = []\n",
    "for i in range(9):\n",
    "    integer_encoded += [i] * 30\n",
    "\n",
    "onehot_encoded = []\n",
    "for elem in integer_encoded:\n",
    "    letter = [0 for i in range(9)]\n",
    "    letter[elem] = 1\n",
    "    onehot_encoded.append(letter)\n",
    "\n",
    "y_train=onehot_encoded\n",
    "x_train=data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing data and do one-hot encoding on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n",
      "370\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# every 30 lines is a different speaker. Each recording is decomposed into 9 arrays of 4 points (9 lines from the original plot)\n",
    "with open('testing_after_PCA_after_taking_5.csv', newline='') as csvfile:\n",
    "    data_test = list(csv.reader(csvfile))\n",
    "\n",
    "\n",
    "# generate labels for the training \n",
    "integer_encoded = [0]*31 + [1]*35 + [2]*88 + [3]*44 + [4]*29 + [5]*24 + [6]*40 + [7]*50 + [8]*29\n",
    "\n",
    "onehot_encoded = []\n",
    "for elem in integer_encoded:\n",
    "    letter = [0 for i in range(9)]\n",
    "    letter[elem] = 1\n",
    "    onehot_encoded.append(letter)\n",
    "\n",
    "y_test=onehot_encoded\n",
    "x_test=data_test\n",
    "print(len(y_test))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data from str to list of ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n",
      "370\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def Convert_to_list_of_ints(data): \n",
    "    t=[]\n",
    "    c=[]\n",
    "    for elem in data:\n",
    "        for i in range(9):\n",
    "            temp = elem[i].strip(string.punctuation)\n",
    "            temp = temp.replace(\" \", \"\")\n",
    "            temp = temp.replace(\"'\",\"\")\n",
    "            temp = list(map(float, temp.split(\",\")))\n",
    "            c.append(temp) #concatenate the sub arrays for each of the 9 lines to make one big array\n",
    "        t.append(c)\n",
    "        c=[]\n",
    "    return t\n",
    "\n",
    "x_train=Convert_to_list_of_ints(x_train)\n",
    "x_test=Convert_to_list_of_ints(x_test)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# shuffle training data\n",
    "c = list(zip(x_train, y_train))\n",
    "random.shuffle(c)\n",
    "x_train, y_train = zip(*c)\n",
    "\n",
    "## Turn the lists into np.arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "## we also have to convert our data into three-dimensional format\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 5,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle testing data\n",
    "b = list(zip(x_test, y_test))\n",
    "random.shuffle(b)\n",
    "x_test, y_test = zip(*b)\n",
    "\n",
    "## Turn the lists into np.arrays\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "\n",
    "## we also have to convert our data into three-dimensional format\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],5,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62\n",
      "  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80\n",
      "  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26]\n",
      "Running Fold 1 / 10\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.2881\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 381us/step - loss: 0.0727 - accuracy: 0.6296\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 389us/step - loss: 0.0620 - accuracy: 0.7243\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 390us/step - loss: 0.0572 - accuracy: 0.7654\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 382us/step - loss: 0.0519 - accuracy: 0.8230\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 398us/step - loss: 0.0488 - accuracy: 0.8436\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 435us/step - loss: 0.0454 - accuracy: 0.8765\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 403us/step - loss: 0.0417 - accuracy: 0.9095\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 406us/step - loss: 0.0411 - accuracy: 0.8765\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 397us/step - loss: 0.0382 - accuracy: 0.9053\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 428us/step - loss: 0.0353 - accuracy: 0.9218\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 460us/step - loss: 0.0374 - accuracy: 0.8971\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 482us/step - loss: 0.0327 - accuracy: 0.9424\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 444us/step - loss: 0.0330 - accuracy: 0.9218\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 437us/step - loss: 0.0318 - accuracy: 0.9177\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 498us/step - loss: 0.0319 - accuracy: 0.9136\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 527us/step - loss: 0.0302 - accuracy: 0.9506\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 430us/step - loss: 0.0259 - accuracy: 0.9465\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 378us/step - loss: 0.0271 - accuracy: 0.9465\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 391us/step - loss: 0.0284 - accuracy: 0.9342\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 425us/step - loss: 0.0275 - accuracy: 0.9424\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 404us/step - loss: 0.0256 - accuracy: 0.9671\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 378us/step - loss: 0.0252 - accuracy: 0.9671\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 417us/step - loss: 0.0244 - accuracy: 0.9588\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 430us/step - loss: 0.0251 - accuracy: 0.9588\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 367us/step - loss: 0.0219 - accuracy: 0.9671\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 423us/step - loss: 0.0229 - accuracy: 0.9630\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 399us/step - loss: 0.0218 - accuracy: 0.9753\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 414us/step - loss: 0.0224 - accuracy: 0.9630\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 389us/step - loss: 0.0210 - accuracy: 0.9794\n",
      "Test loss: 0.02347448095679283\n",
      "Test accuracy: 0.9259259104728699\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  54  55  56  57  58  59  60  61  62\n",
      "  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80\n",
      "  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n",
      " 51 52 53]\n",
      "Running Fold 2 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.2263\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 391us/step - loss: 0.0755 - accuracy: 0.6214\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 429us/step - loss: 0.0642 - accuracy: 0.7202\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 445us/step - loss: 0.0588 - accuracy: 0.7984\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 447us/step - loss: 0.0546 - accuracy: 0.7778\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 437us/step - loss: 0.0479 - accuracy: 0.8683\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 386us/step - loss: 0.0450 - accuracy: 0.8765\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 406us/step - loss: 0.0436 - accuracy: 0.8724\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 393us/step - loss: 0.0401 - accuracy: 0.8930\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 377us/step - loss: 0.0404 - accuracy: 0.8889\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 415us/step - loss: 0.0349 - accuracy: 0.9218\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 435us/step - loss: 0.0334 - accuracy: 0.9136\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 389us/step - loss: 0.0322 - accuracy: 0.9506\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 413us/step - loss: 0.0309 - accuracy: 0.9547\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 388us/step - loss: 0.0315 - accuracy: 0.9342\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 413us/step - loss: 0.0315 - accuracy: 0.9424\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 386us/step - loss: 0.0280 - accuracy: 0.9506\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 443us/step - loss: 0.0281 - accuracy: 0.9383\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 404us/step - loss: 0.0273 - accuracy: 0.9383\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 390us/step - loss: 0.0283 - accuracy: 0.9259\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 390us/step - loss: 0.0274 - accuracy: 0.9383\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 414us/step - loss: 0.0266 - accuracy: 0.9506\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 422us/step - loss: 0.0251 - accuracy: 0.9630\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 383us/step - loss: 0.0236 - accuracy: 0.9712\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 428us/step - loss: 0.0263 - accuracy: 0.9547\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 388us/step - loss: 0.0236 - accuracy: 0.9465\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 424us/step - loss: 0.0230 - accuracy: 0.9588\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 373us/step - loss: 0.0231 - accuracy: 0.9794\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 385us/step - loss: 0.0252 - accuracy: 0.9671\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 368us/step - loss: 0.0226 - accuracy: 0.9630\n",
      "Test loss: 0.013216836377978325\n",
      "Test accuracy: 0.9629629850387573\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77\n",
      " 78 79 80]\n",
      "Running Fold 3 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.3868\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 381us/step - loss: 0.0745 - accuracy: 0.5720\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 372us/step - loss: 0.0633 - accuracy: 0.7243\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 373us/step - loss: 0.0581 - accuracy: 0.7490\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 384us/step - loss: 0.0526 - accuracy: 0.8189\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 365us/step - loss: 0.0483 - accuracy: 0.8477\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 379us/step - loss: 0.0442 - accuracy: 0.8930\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 364us/step - loss: 0.0444 - accuracy: 0.8971\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 381us/step - loss: 0.0408 - accuracy: 0.8930\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 401us/step - loss: 0.0386 - accuracy: 0.9095\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 362us/step - loss: 0.0349 - accuracy: 0.9383\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 395us/step - loss: 0.0316 - accuracy: 0.9300\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 383us/step - loss: 0.0354 - accuracy: 0.8889\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 382us/step - loss: 0.0324 - accuracy: 0.9259\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 396us/step - loss: 0.0314 - accuracy: 0.9259\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 370us/step - loss: 0.0304 - accuracy: 0.9383\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 380us/step - loss: 0.0284 - accuracy: 0.9342\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 401us/step - loss: 0.0280 - accuracy: 0.9383\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 392us/step - loss: 0.0272 - accuracy: 0.9424\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 374us/step - loss: 0.0278 - accuracy: 0.9465\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 387us/step - loss: 0.0265 - accuracy: 0.9547\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 386us/step - loss: 0.0248 - accuracy: 0.9465\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 373us/step - loss: 0.0236 - accuracy: 0.9424\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 381us/step - loss: 0.0246 - accuracy: 0.9424\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 406us/step - loss: 0.0237 - accuracy: 0.9588\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 372us/step - loss: 0.0251 - accuracy: 0.9424\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 381us/step - loss: 0.0236 - accuracy: 0.9588\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 360us/step - loss: 0.0205 - accuracy: 0.9671\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 369us/step - loss: 0.0222 - accuracy: 0.9671\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 381us/step - loss: 0.0208 - accuracy: 0.9753\n",
      "Test loss: 0.02045896090567112\n",
      "Test accuracy: 1.0\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80 108 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [ 81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107]\n",
      "Running Fold 4 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.2469\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 399us/step - loss: 0.0760 - accuracy: 0.6337\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 387us/step - loss: 0.0651 - accuracy: 0.7037\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 379us/step - loss: 0.0579 - accuracy: 0.7901\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 399us/step - loss: 0.0546 - accuracy: 0.8025\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 388us/step - loss: 0.0502 - accuracy: 0.8519\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 396us/step - loss: 0.0473 - accuracy: 0.8560\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 383us/step - loss: 0.0431 - accuracy: 0.8560\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 396us/step - loss: 0.0428 - accuracy: 0.8642\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 386us/step - loss: 0.0409 - accuracy: 0.8848\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 388us/step - loss: 0.0400 - accuracy: 0.8807\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 378us/step - loss: 0.0354 - accuracy: 0.9136\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 379us/step - loss: 0.0341 - accuracy: 0.8971\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 377us/step - loss: 0.0330 - accuracy: 0.9300\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 366us/step - loss: 0.0324 - accuracy: 0.9218\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 413us/step - loss: 0.0313 - accuracy: 0.9300\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 378us/step - loss: 0.0314 - accuracy: 0.9218\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 376us/step - loss: 0.0287 - accuracy: 0.9465\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 381us/step - loss: 0.0292 - accuracy: 0.9547\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 397us/step - loss: 0.0305 - accuracy: 0.9259\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 372us/step - loss: 0.0260 - accuracy: 0.9630\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 378us/step - loss: 0.0268 - accuracy: 0.9383\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 384us/step - loss: 0.0248 - accuracy: 0.9588\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 377us/step - loss: 0.0259 - accuracy: 0.9630\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 374us/step - loss: 0.0260 - accuracy: 0.9506\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 392us/step - loss: 0.0252 - accuracy: 0.9465\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 370us/step - loss: 0.0243 - accuracy: 0.9465\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 383us/step - loss: 0.0251 - accuracy: 0.9547\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 352us/step - loss: 0.0231 - accuracy: 0.9753\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 384us/step - loss: 0.0228 - accuracy: 0.9794\n",
      "Test loss: 0.01595645770430565\n",
      "Test accuracy: 1.0\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134]\n",
      "Running Fold 5 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.2593\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 403us/step - loss: 0.0746 - accuracy: 0.5720\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 376us/step - loss: 0.0645 - accuracy: 0.7325\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 386us/step - loss: 0.0562 - accuracy: 0.8230\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 397us/step - loss: 0.0551 - accuracy: 0.8025\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 382us/step - loss: 0.0478 - accuracy: 0.8477\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 384us/step - loss: 0.0472 - accuracy: 0.8395\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 385us/step - loss: 0.0427 - accuracy: 0.9053\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 388us/step - loss: 0.0412 - accuracy: 0.8683\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 395us/step - loss: 0.0378 - accuracy: 0.9342\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 376us/step - loss: 0.0375 - accuracy: 0.9095\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 383us/step - loss: 0.0351 - accuracy: 0.9342\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 386us/step - loss: 0.0338 - accuracy: 0.9053\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 374us/step - loss: 0.0328 - accuracy: 0.9342\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 388us/step - loss: 0.0300 - accuracy: 0.9218\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 394us/step - loss: 0.0310 - accuracy: 0.9218\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 375us/step - loss: 0.0304 - accuracy: 0.9259\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 390us/step - loss: 0.0298 - accuracy: 0.9506\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 396us/step - loss: 0.0264 - accuracy: 0.9588\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 376us/step - loss: 0.0256 - accuracy: 0.9465\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 376us/step - loss: 0.0273 - accuracy: 0.9259\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 404us/step - loss: 0.0240 - accuracy: 0.9506\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 386us/step - loss: 0.0264 - accuracy: 0.9259\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 380us/step - loss: 0.0241 - accuracy: 0.9630\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 388us/step - loss: 0.0226 - accuracy: 0.9630\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 390us/step - loss: 0.0236 - accuracy: 0.9547\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 401us/step - loss: 0.0248 - accuracy: 0.9465\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 391us/step - loss: 0.0225 - accuracy: 0.9753\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 377us/step - loss: 0.0238 - accuracy: 0.9671\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 411us/step - loss: 0.0218 - accuracy: 0.9671\n",
      "Test loss: 0.027624424546957016\n",
      "Test accuracy: 0.8888888955116272\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161]\n",
      "Running Fold 6 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.3416\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 410us/step - loss: 0.0718 - accuracy: 0.6955\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 395us/step - loss: 0.0639 - accuracy: 0.7407\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 383us/step - loss: 0.0569 - accuracy: 0.7778\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 380us/step - loss: 0.0500 - accuracy: 0.8395\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 389us/step - loss: 0.0491 - accuracy: 0.8601\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 401us/step - loss: 0.0437 - accuracy: 0.8889\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 391us/step - loss: 0.0402 - accuracy: 0.8848\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 382us/step - loss: 0.0398 - accuracy: 0.8765\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 378us/step - loss: 0.0374 - accuracy: 0.9177\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 402us/step - loss: 0.0375 - accuracy: 0.8889\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 390us/step - loss: 0.0353 - accuracy: 0.8724\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 386us/step - loss: 0.0336 - accuracy: 0.9300\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 385us/step - loss: 0.0345 - accuracy: 0.8930\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 392us/step - loss: 0.0296 - accuracy: 0.9383\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 393us/step - loss: 0.0301 - accuracy: 0.9383\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 391us/step - loss: 0.0304 - accuracy: 0.9300\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 385us/step - loss: 0.0284 - accuracy: 0.9383\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 379us/step - loss: 0.0278 - accuracy: 0.9465\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 394us/step - loss: 0.0270 - accuracy: 0.9424\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 389us/step - loss: 0.0257 - accuracy: 0.9588\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 401us/step - loss: 0.0261 - accuracy: 0.9424\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 372us/step - loss: 0.0265 - accuracy: 0.9588\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 382us/step - loss: 0.0251 - accuracy: 0.9506\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 399us/step - loss: 0.0232 - accuracy: 0.9630\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 379us/step - loss: 0.0226 - accuracy: 0.9671\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 389us/step - loss: 0.0230 - accuracy: 0.9753\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 387us/step - loss: 0.0219 - accuracy: 0.9794\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 393us/step - loss: 0.0219 - accuracy: 0.9300\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 396us/step - loss: 0.0224 - accuracy: 0.9671\n",
      "Test loss: 0.023177094757556915\n",
      "Test accuracy: 0.9259259104728699\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188]\n",
      "Running Fold 7 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.3498\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 394us/step - loss: 0.0712 - accuracy: 0.6584\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 394us/step - loss: 0.0642 - accuracy: 0.71190s - loss: 0.0654 - accuracy: 0.66\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 398us/step - loss: 0.0574 - accuracy: 0.7695\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 407us/step - loss: 0.0551 - accuracy: 0.7654\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 403us/step - loss: 0.0494 - accuracy: 0.8272\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 501us/step - loss: 0.0433 - accuracy: 0.8477\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 482us/step - loss: 0.0417 - accuracy: 0.8724\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 597us/step - loss: 0.0395 - accuracy: 0.9053\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 499us/step - loss: 0.0367 - accuracy: 0.9053\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 471us/step - loss: 0.0371 - accuracy: 0.8889\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 440us/step - loss: 0.0342 - accuracy: 0.9095\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 461us/step - loss: 0.0336 - accuracy: 0.9012\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 446us/step - loss: 0.0336 - accuracy: 0.9177\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 471us/step - loss: 0.0314 - accuracy: 0.9177\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 466us/step - loss: 0.0300 - accuracy: 0.9342\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 445us/step - loss: 0.0304 - accuracy: 0.9136\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 438us/step - loss: 0.0293 - accuracy: 0.9342\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 455us/step - loss: 0.0291 - accuracy: 0.9259\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 447us/step - loss: 0.0288 - accuracy: 0.9342\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 437us/step - loss: 0.0289 - accuracy: 0.9300\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 436us/step - loss: 0.0254 - accuracy: 0.9506\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 424us/step - loss: 0.0268 - accuracy: 0.9424\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 442us/step - loss: 0.0245 - accuracy: 0.9547\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 439us/step - loss: 0.0256 - accuracy: 0.9300\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 469us/step - loss: 0.0246 - accuracy: 0.9424\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 471us/step - loss: 0.0233 - accuracy: 0.9671\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 492us/step - loss: 0.0238 - accuracy: 0.9712\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 447us/step - loss: 0.0221 - accuracy: 0.9753\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 468us/step - loss: 0.0245 - accuracy: 0.9630\n",
      "Test loss: 0.016185492277145386\n",
      "Test accuracy: 0.9629629850387573\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215]\n",
      "Running Fold 8 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.3827\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 440us/step - loss: 0.0717 - accuracy: 0.6831\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 486us/step - loss: 0.0616 - accuracy: 0.7325\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 528us/step - loss: 0.0537 - accuracy: 0.8025\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 476us/step - loss: 0.0502 - accuracy: 0.8189\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 412us/step - loss: 0.0482 - accuracy: 0.8107\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 419us/step - loss: 0.0429 - accuracy: 0.8807\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 522us/step - loss: 0.0425 - accuracy: 0.8560\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 448us/step - loss: 0.0392 - accuracy: 0.8807\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 400us/step - loss: 0.0378 - accuracy: 0.9053\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 385us/step - loss: 0.0353 - accuracy: 0.9136\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 375us/step - loss: 0.0342 - accuracy: 0.9218\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 402us/step - loss: 0.0326 - accuracy: 0.9177\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 431us/step - loss: 0.0338 - accuracy: 0.9053\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 673us/step - loss: 0.0319 - accuracy: 0.9136\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 414us/step - loss: 0.0309 - accuracy: 0.9342\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 420us/step - loss: 0.0281 - accuracy: 0.9300\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 401us/step - loss: 0.0310 - accuracy: 0.9177\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 393us/step - loss: 0.0292 - accuracy: 0.9424\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 399us/step - loss: 0.0278 - accuracy: 0.9547\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 408us/step - loss: 0.0285 - accuracy: 0.9342\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 406us/step - loss: 0.0281 - accuracy: 0.9218\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 413us/step - loss: 0.0282 - accuracy: 0.9465\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 392us/step - loss: 0.0245 - accuracy: 0.9383\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 417us/step - loss: 0.0226 - accuracy: 0.9547\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 401us/step - loss: 0.0252 - accuracy: 0.9424\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 415us/step - loss: 0.0245 - accuracy: 0.9588\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 407us/step - loss: 0.0234 - accuracy: 0.9424\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 455us/step - loss: 0.0232 - accuracy: 0.9465\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 454us/step - loss: 0.0226 - accuracy: 0.9547\n",
      "Test loss: 0.02106611616909504\n",
      "Test accuracy: 0.9629629850387573\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242]\n",
      "Running Fold 9 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.3210\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 466us/step - loss: 0.0709 - accuracy: 0.6091\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 476us/step - loss: 0.0627 - accuracy: 0.6996\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 431us/step - loss: 0.0563 - accuracy: 0.7695\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 394us/step - loss: 0.0521 - accuracy: 0.8230\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 407us/step - loss: 0.0485 - accuracy: 0.8436\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 492us/step - loss: 0.0431 - accuracy: 0.8724\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 550us/step - loss: 0.0409 - accuracy: 0.8765\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 495us/step - loss: 0.0369 - accuracy: 0.9177\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 398us/step - loss: 0.0376 - accuracy: 0.8930\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 397us/step - loss: 0.0351 - accuracy: 0.9053\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 397us/step - loss: 0.0343 - accuracy: 0.9136\n",
      "Epoch 13/30\n",
      "243/243 [==============================] - 0s 399us/step - loss: 0.0350 - accuracy: 0.8971\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 403us/step - loss: 0.0330 - accuracy: 0.9053\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 404us/step - loss: 0.0320 - accuracy: 0.9218\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 434us/step - loss: 0.0298 - accuracy: 0.9383\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 472us/step - loss: 0.0270 - accuracy: 0.9588\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 485us/step - loss: 0.0283 - accuracy: 0.9383\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 456us/step - loss: 0.0262 - accuracy: 0.9506\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 442us/step - loss: 0.0280 - accuracy: 0.9342\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 448us/step - loss: 0.0260 - accuracy: 0.9506\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 491us/step - loss: 0.0252 - accuracy: 0.9342\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 463us/step - loss: 0.0253 - accuracy: 0.9342\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 440us/step - loss: 0.0228 - accuracy: 0.9712\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 445us/step - loss: 0.0235 - accuracy: 0.9506\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 427us/step - loss: 0.0229 - accuracy: 0.9588\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 458us/step - loss: 0.0235 - accuracy: 0.9424\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 410us/step - loss: 0.0232 - accuracy: 0.9712\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 439us/step - loss: 0.0226 - accuracy: 0.9671\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 414us/step - loss: 0.0207 - accuracy: 0.9712\n",
      "Test loss: 0.02101689577102661\n",
      "Test accuracy: 0.9259259104728699\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242] [243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269]\n",
      "Running Fold 10 / 10\n",
      "Epoch 1/30\n",
      "243/243 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.3045\n",
      "Epoch 2/30\n",
      "243/243 [==============================] - 0s 420us/step - loss: 0.0715 - accuracy: 0.6749\n",
      "Epoch 3/30\n",
      "243/243 [==============================] - 0s 446us/step - loss: 0.0645 - accuracy: 0.7243\n",
      "Epoch 4/30\n",
      "243/243 [==============================] - 0s 421us/step - loss: 0.0584 - accuracy: 0.7654\n",
      "Epoch 5/30\n",
      "243/243 [==============================] - 0s 497us/step - loss: 0.0518 - accuracy: 0.8436\n",
      "Epoch 6/30\n",
      "243/243 [==============================] - 0s 456us/step - loss: 0.0494 - accuracy: 0.8807\n",
      "Epoch 7/30\n",
      "243/243 [==============================] - 0s 415us/step - loss: 0.0446 - accuracy: 0.8642\n",
      "Epoch 8/30\n",
      "243/243 [==============================] - 0s 421us/step - loss: 0.0442 - accuracy: 0.8436\n",
      "Epoch 9/30\n",
      "243/243 [==============================] - 0s 414us/step - loss: 0.0394 - accuracy: 0.8848\n",
      "Epoch 10/30\n",
      "243/243 [==============================] - 0s 439us/step - loss: 0.0416 - accuracy: 0.8807\n",
      "Epoch 11/30\n",
      "243/243 [==============================] - 0s 446us/step - loss: 0.0368 - accuracy: 0.9095\n",
      "Epoch 12/30\n",
      "243/243 [==============================] - 0s 417us/step - loss: 0.0369 - accuracy: 0.9012\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 426us/step - loss: 0.0328 - accuracy: 0.9300\n",
      "Epoch 14/30\n",
      "243/243 [==============================] - 0s 428us/step - loss: 0.0330 - accuracy: 0.9053\n",
      "Epoch 15/30\n",
      "243/243 [==============================] - 0s 426us/step - loss: 0.0332 - accuracy: 0.9259\n",
      "Epoch 16/30\n",
      "243/243 [==============================] - 0s 454us/step - loss: 0.0307 - accuracy: 0.9383\n",
      "Epoch 17/30\n",
      "243/243 [==============================] - 0s 464us/step - loss: 0.0284 - accuracy: 0.9342\n",
      "Epoch 18/30\n",
      "243/243 [==============================] - 0s 443us/step - loss: 0.0282 - accuracy: 0.9465\n",
      "Epoch 19/30\n",
      "243/243 [==============================] - 0s 443us/step - loss: 0.0299 - accuracy: 0.9342\n",
      "Epoch 20/30\n",
      "243/243 [==============================] - 0s 429us/step - loss: 0.0250 - accuracy: 0.9547\n",
      "Epoch 21/30\n",
      "243/243 [==============================] - 0s 449us/step - loss: 0.0269 - accuracy: 0.9547\n",
      "Epoch 22/30\n",
      "243/243 [==============================] - 0s 433us/step - loss: 0.0268 - accuracy: 0.9465\n",
      "Epoch 23/30\n",
      "243/243 [==============================] - 0s 463us/step - loss: 0.0253 - accuracy: 0.9465\n",
      "Epoch 24/30\n",
      "243/243 [==============================] - 0s 447us/step - loss: 0.0259 - accuracy: 0.9424\n",
      "Epoch 25/30\n",
      "243/243 [==============================] - 0s 394us/step - loss: 0.0233 - accuracy: 0.9671\n",
      "Epoch 26/30\n",
      "243/243 [==============================] - 0s 385us/step - loss: 0.0241 - accuracy: 0.9465\n",
      "Epoch 27/30\n",
      "243/243 [==============================] - 0s 390us/step - loss: 0.0230 - accuracy: 0.9547\n",
      "Epoch 28/30\n",
      "243/243 [==============================] - 0s 403us/step - loss: 0.0243 - accuracy: 0.9506\n",
      "Epoch 29/30\n",
      "243/243 [==============================] - 0s 424us/step - loss: 0.0223 - accuracy: 0.9671\n",
      "Epoch 30/30\n",
      "243/243 [==============================] - 0s 391us/step - loss: 0.0230 - accuracy: 0.9383\n",
      "Test loss: 0.019593657925724983\n",
      "Test accuracy: 0.9259259104728699\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding, BatchNormalization, Activation\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.regularizers import L1L2\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "##model.add(Bidirectional(LSTM(50, activation='relu',return_sequences=True,kernel_regularizer=L1L2(l1=0.0, l2=0.0)), input_shape=(x_train.shape[1], 9)))\n",
    "    model.add(LSTM(units=90,activation='tanh', recurrent_activation='sigmoid', return_sequences=False,input_shape=(x_train.shape[1], 9),dropout=0.2,recurrent_dropout=0.2)) \n",
    "##model.add(BatchNormalization())\n",
    "##model.add(LSTM(units=90,activation='relu', recurrent_activation='sigmoid', return_sequences=True,dropout=0.34,recurrent_dropout=0.34))\n",
    "##model.add(LSTM(units=90, activation='relu', recurrent_activation='sigmoid',return_sequences=False,dropout=0.34,recurrent_dropout=0.34))\n",
    "    model.add(Dense(units=9))\n",
    "    model.add(Activation(\"linear\")) \n",
    "    opt= keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer = opt, loss = 'mean_squared_error',metrics = ['accuracy'])\n",
    "    return model\n",
    "#model.fit(x_train, y_train, batch_size=27, epochs=2) #was 150\n",
    "\n",
    "# saving the model\n",
    "#model.save('keras_ML1.h5')\n",
    "\n",
    "\n",
    "#FIRST TEST K-FOLD\n",
    "def train_and_evaluate_model(model, data, labels, Data, Labels):\n",
    "    model.fit(data, labels, batch_size=9, epochs=30) #was 150 #training subset\n",
    "    score = model.evaluate(Data, Labels, verbose=0) #testing subset\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    return score\n",
    "    # fit and evaluate here.\n",
    "\n",
    "Test_Loss = []\n",
    "Test_Accuracy = []\n",
    "    \n",
    "from sklearn.model_selection import KFold\n",
    "#if __name__ == \"__main__\":\n",
    "data, labels = x_train, y_train\n",
    "kf = KFold(n_splits=10) \n",
    "i=0\n",
    "for train, test in kf.split(x_train):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "    i=i+1\n",
    "    print(\"Running Fold\", i,\"/\", 10)\n",
    "    model = None # Clearing the NN.\n",
    "    model = create_model()\n",
    "    score = train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])\n",
    "    Test_Loss.append(score[0])\n",
    "    Test_Accuracy.append(score[1])\n",
    "    \n",
    "model.save('keras_ML1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9259259104728699,\n",
       " 0.9629629850387573,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.8888888955116272,\n",
       " 0.9259259104728699,\n",
       " 0.9629629850387573,\n",
       " 0.9629629850387573,\n",
       " 0.9259259104728699,\n",
       " 0.9259259104728699]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02347448095679283,\n",
       " 0.013216836377978325,\n",
       " 0.02045896090567112,\n",
       " 0.01595645770430565,\n",
       " 0.027624424546957016,\n",
       " 0.023177094757556915,\n",
       " 0.016185492277145386,\n",
       " 0.02106611616909504,\n",
       " 0.02101689577102661,\n",
       " 0.019593657925724983]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.051044314616435285\n",
      "Test accuracy: 0.7810810804367065\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# testing the model\n",
    "model = load_model('keras_ML1.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
